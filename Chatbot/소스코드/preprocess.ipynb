{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kiwipiepy import Kiwi\n",
    "from soyspacing.countbase import CountSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv2data(*df):\n",
    "    \n",
    "    \"\"\"\n",
    "    csv 파일은 필수적으로 내용(질문)을 가지고 있어야한다.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    df_lst = list(df)\n",
    "    merged_df_lst = []\n",
    "    for df in df_lst:\n",
    "        col = df.columns.tolist()\n",
    "\n",
    "        if '내용' not in col:\n",
    "            print(\"내용이 없습니다\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        col_nme = []\n",
    "        not_need = []\n",
    "        for name in col:\n",
    "            if '내용' == name:\n",
    "                col_nme.append('내용')\n",
    "                col.remove(name)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        for name in col:\n",
    "            if '댓글' == name:\n",
    "                col_nme.append('댓글')\n",
    "                col.remove(name)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "\n",
    "        df = df.drop(col, axis=1)\n",
    "        if '댓글' not in df.columns.tolist():\n",
    "            df['댓글'] = np.nan\n",
    "        df['TAGSET'] = np.nan\n",
    "        df.rename(columns={\"내용\":\"QUESTION\", \"댓글\":\"ANSWER\"}, inplace=True)\n",
    "        \n",
    "        merged_df_lst.append(df)\n",
    "\n",
    "    # 데이터 병합\n",
    "    merged_df = pd.concat(merged_df_lst)\n",
    "    merged_df.reset_index(drop=True, inplace=True)\n",
    "    merged_df = merged_df[['QUESTION', \"ANSWER\", \"TAGSET\"]]\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(merged_df, space_model_path, stop_word_path, result_file_name):\n",
    "    \"\"\"\n",
    "    import os, re, csv\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from kiwipiepy import Kiwi\n",
    "    from soyspacing.countbase import CountSpace\n",
    "\n",
    "    pip install soyspace\n",
    "    pip install kiwipiepy\n",
    "\n",
    "    model : soy_space_model (자료 폴더에있음)\n",
    " model : soy_space_model (자료 폴더에있음)\n",
    "    stop_word : 자료 파일에 있음\n",
    "\n",
    "    \"\"\"\n",
    "        \n",
    "    model = CountSpace()\n",
    "    model.load_model(space_model_path, json_format=False)\n",
    "\n",
    "    # 질문 리스트화\n",
    "    question_list = merged_df['QUESTION'].tolist()\n",
    "\n",
    "    # 띄어쓰기 시작\n",
    "    soy_corrected_question = []\n",
    "    for x in question_list:\n",
    "        corrected = model.correct(x)\n",
    "        soy_corrected_question.append(corrected)\n",
    "\n",
    "    spaced_quest = []\n",
    "    for quest, tag in soy_corrected_question:\n",
    "        if type(quest) == str:\n",
    "            spaced_quest.append(quest)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "\n",
    "    # 정규표현식으로 정규화\n",
    "    norm_content = []\n",
    "    for text in spaced_quest:\n",
    "        punct = re.compile(r'[\\~\\'\\\"\\.\\,\\?\\!\\:\\;\\)\\(\\+]+') \n",
    "        norm_text = re.sub(punct, \"\", text)\n",
    "        norm_text = re.sub(r'(안녕)+(하세요)?', '', norm_text)\n",
    "        norm_text = re.sub(r'(조교)[님]?', \"\", norm_text)\n",
    "        norm_text = re.sub(r'[ㄱ-ㅎㅏ-ㅣ]+', '', norm_text) # ㅠ하나 쓰는 놈들꺼 제거...\n",
    "        norm_text = re.sub( r\"\\s{2,}\",\" \", norm_text) \n",
    "        norm_text = re.sub( r\"\\A\\s+\",'', norm_text)\n",
    "        norm_text = re.sub(r\"([가-힣]+)[여용염]\",r\"\\1요\",norm_text) # 용용체 제거 슈바끄...\n",
    "        norm_text = re.sub(r\"\\b이중[^전공]*?\\b\",\"이중전공\",norm_text) # 이중으로만 적혀있는거 변형\n",
    "        norm_text = re.sub(r\"\\b부전[^공]*?\\b\",\"부전공\",norm_text) # 부전으로만 적혀있는거 변형\n",
    "\n",
    "        # 줄인말제거\n",
    "        norm_text = re.sub(r\"\\b전심[가-힣]*\\b\", \"전공심화\", norm_text)\n",
    "        norm_text = re.sub(r\"\\b융전[가-힣]*\\b\", \"융합전공\", norm_text)\n",
    "        norm_text = re.sub(r'\\b연계전공\\b', '융합전공', norm_text) # 단어 통일화\n",
    "        \n",
    "        norm_content.append(norm_text)\n",
    "\n",
    "    # 데이터프레임에 병합\n",
    "    merged_df['QUESTION'] = norm_content\n",
    "\n",
    "    # 형태소 분석\n",
    "\n",
    "    kiwi = Kiwi()\n",
    "\n",
    "    #대분류 사전 추가\n",
    "    kiwi.add_user_word('이중전공', 'DM', 20.0)\n",
    "    kiwi.add_user_word('융합전공', 'UM', 20.0)\n",
    "    kiwi.add_user_word('전공심화', 'MD', 20.0)\n",
    "    kiwi.add_user_word('부전공', 'SM', 20.0)\n",
    "    kiwi.add_user_word('연계전공', 'UM', 20.0)\n",
    "\n",
    "    kiwi.prepare()\n",
    "\n",
    "    ## 형태소 분석\n",
    "    sent = ''\n",
    "    lem_cont = []\n",
    "    for quest in norm_content:\n",
    "        ## 형태소만 떼어내기\n",
    "        temp_tagging = [x[0] for x in kiwi.analyze(quest, top_n=1)]\n",
    "        inner_temp = [\"{}/{}\".format(word, tag) for word, tag, score1, score2 in temp_tagging[0]]\n",
    "        lem_cont.append(inner_temp)\n",
    "\n",
    "    ## 불용어 처리 ##\n",
    "\n",
    "    stop_file = open(stop_word_path,'r', encoding = 'utf8')\n",
    "    lines = stop_file.readlines()\n",
    "    stop_file.close()\n",
    "    stop_words = lines[0].split()\n",
    "\n",
    "    listed_cont = [[comb.split('/') for comb in sent] for sent in lem_cont]\n",
    "\n",
    "    main_texts = []\n",
    "    non_mean = []\n",
    "    for sent in listed_cont:\n",
    "        texts = []\n",
    "        for word in sent:\n",
    "            # 한 글자 제거\n",
    "            if len(word[0]) > 1:\n",
    "                # 조사 등 불필요한 거 제거\n",
    "                if 'N' in word[-1]:\n",
    "                    texts.append(word[0])\n",
    "                elif '@' in word[-1]:\n",
    "                    texts.append(word[0])\n",
    "                elif 'V' in word[-1]:\n",
    "                    texts.append(word[0])\n",
    "                else:\n",
    "                    non_mean.append(word[0])\n",
    "            else:\n",
    "                non_mean.append(word[0])\n",
    "        \n",
    "        main_texts.append(texts)\n",
    "\n",
    "    lemmatized_question = []\n",
    "\n",
    "    for noun in main_texts:\n",
    "        txt = ' '.join(noun)\n",
    "        lemmatized_question.append(txt)\n",
    "\n",
    "    merged_df['LEMMA'] = lemmatized_question\n",
    "\n",
    "    ##Tagset 달기\n",
    "    tagset = []\n",
    "    for sent in main_texts:\n",
    "        tags = []\n",
    "        for word in sent:\n",
    "            if '이중전공' == word:\n",
    "                tags.append(\"DM\")\n",
    "            elif '부전공' == word:\n",
    "                tags.append(\"SM\")\n",
    "            elif '전공심화' == word:\n",
    "                tags.append(\"MD\")\n",
    "            elif '융합전공' == word:\n",
    "                tags.append(\"UM\")\n",
    "            else:\n",
    "                tags.append(\"UK\")\n",
    "        tagset.append(tags)\n",
    "\n",
    "    tagsets = []\n",
    "    for sent_tag in tagset:\n",
    "        tagsets.append(list(set(sent_tag)))\n",
    "\n",
    "    for tags in tagsets:\n",
    "        if len(tags) > 1:\n",
    "            del tags[-1]\n",
    "\n",
    "    merged_df['TAGSET'] = tagsets\n",
    "\n",
    "    # csv로 출력\n",
    "    path = os.getcwd()\n",
    "    merged_df.to_csv(path + \"\\\\\" + result_file_name + \".csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eta_df = pd.read_csv(r\"D:\\Shin\\Develop\\python\\NLP\\howls_nlp\\Chatbot\\자료\\질문.csv\", encoding='ANSI')\n",
    "# eta2_df = pd.read_csv(r\"D:\\Shin\\Develop\\python\\NLP\\howls_nlp\\Chatbot\\자료\\질문2.csv\", encoding='ANSI')\n",
    "# dm_df = pd.read_csv(r\"D:\\Shin\\Develop\\python\\NLP\\howls_nlp\\Chatbot\\자료\\이중전과게시판_이중검색.csv\", encoding='UTF-8')\n",
    "double_major_df = pd.read_excel(r\"E:\\Programming\\python\\NLP\\howls_nlp\\Chatbot\\자료\\이중전공_howls.xlsx\")\n",
    "um_df = pd.read_excel(r\"E:\\Programming\\python\\NLP\\howls_nlp\\Chatbot\\자료\\융합전공_질문_답변.xlsx\")\n",
    "\n",
    "merged_df = csv2data(double_major_df, um_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                           QUESTION  \\\n0           서울캠에서 네덜란드어전공을 들을 수 있나요   \n1                서울캠에서 경영학 들을 수 있나요   \n2        언어와공학 이중전공 서울캠 수업 들을 수 있어요   \n3                 편입생도 이중전공 할 수 있어요   \n4               네덜란드어전공은 어느캠퍼스에서 들어   \n..                              ...   \n120                     광역특화전공이 뭔가요   \n121                   디지털인문학전공이 뭔가요   \n122        디지털인문학전공의 연계기초과목엔 뭐가 있나요   \n123  디지털인문학전공 연계기초 과목 학점인정은 어떻게 하나요   \n124             EU전공 졸업 요건은 어떻게 되나요   \n\n                                                ANSWER TAGSET  \\\n0                                                  아니요   [UK]   \n1                                                  아니요   [UK]   \n2                                        네. 들을 수 있습니다.   [DM]   \n3    네. 필수는 아니지만 재학 연한 내에서 이중전공, 부전공 또는 전공 심화 과정을 이...   [DM]   \n4                                    서울캠퍼스에서 이수해야 합니다.   [UK]   \n..                                                 ...    ...   \n120  국가주도 CK-Ⅱ 사업의 일환으로 2015학년도부터 신설되는 ‘광역특화’ 융합전 공...   [UK]   \n121  한국의 인문학적 전통과 문화에 대한 심층적 지식을 바탕으로 디지털 매체를 활용한 해...   [UK]   \n122  한국철학사(철학과), 한국사입문(사학과) 또는 한국문화사(사학 부전공), KFL문법...   [UK]   \n123  수강신청 후 학사종합지원센터 단과대 교학파트(본인 1전공 소속 기준)에 방문하여 이...   [UK]   \n124                                 논술형 종합시험으로 실시합니다.    [UK]   \n\n                            LEMMA  \n0                    서울캠 네덜란드어 전공  \n1                         서울캠 경영학  \n2                언어 공학 이중전공 서울 수업  \n3                      편입 생도 이중전공  \n4                    네덜란드어 전공 캠퍼스  \n..                            ...  \n120                      광역 특화 전공  \n121                    디지털 인문학 전공  \n122            디지털 문학 전공 연계 기초 과목  \n123  디지털 인문학 전공 연계 기초 과목 학점 인정 어떻  \n124                      전공 졸업 요건  \n\n[125 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>QUESTION</th>\n      <th>ANSWER</th>\n      <th>TAGSET</th>\n      <th>LEMMA</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>서울캠에서 네덜란드어전공을 들을 수 있나요</td>\n      <td>아니요</td>\n      <td>[UK]</td>\n      <td>서울캠 네덜란드어 전공</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>서울캠에서 경영학 들을 수 있나요</td>\n      <td>아니요</td>\n      <td>[UK]</td>\n      <td>서울캠 경영학</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>언어와공학 이중전공 서울캠 수업 들을 수 있어요</td>\n      <td>네. 들을 수 있습니다.</td>\n      <td>[DM]</td>\n      <td>언어 공학 이중전공 서울 수업</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>편입생도 이중전공 할 수 있어요</td>\n      <td>네. 필수는 아니지만 재학 연한 내에서 이중전공, 부전공 또는 전공 심화 과정을 이...</td>\n      <td>[DM]</td>\n      <td>편입 생도 이중전공</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>네덜란드어전공은 어느캠퍼스에서 들어</td>\n      <td>서울캠퍼스에서 이수해야 합니다.</td>\n      <td>[UK]</td>\n      <td>네덜란드어 전공 캠퍼스</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>광역특화전공이 뭔가요</td>\n      <td>국가주도 CK-Ⅱ 사업의 일환으로 2015학년도부터 신설되는 ‘광역특화’ 융합전 공...</td>\n      <td>[UK]</td>\n      <td>광역 특화 전공</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>디지털인문학전공이 뭔가요</td>\n      <td>한국의 인문학적 전통과 문화에 대한 심층적 지식을 바탕으로 디지털 매체를 활용한 해...</td>\n      <td>[UK]</td>\n      <td>디지털 인문학 전공</td>\n    </tr>\n    <tr>\n      <th>122</th>\n      <td>디지털인문학전공의 연계기초과목엔 뭐가 있나요</td>\n      <td>한국철학사(철학과), 한국사입문(사학과) 또는 한국문화사(사학 부전공), KFL문법...</td>\n      <td>[UK]</td>\n      <td>디지털 문학 전공 연계 기초 과목</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>디지털인문학전공 연계기초 과목 학점인정은 어떻게 하나요</td>\n      <td>수강신청 후 학사종합지원센터 단과대 교학파트(본인 1전공 소속 기준)에 방문하여 이...</td>\n      <td>[UK]</td>\n      <td>디지털 인문학 전공 연계 기초 과목 학점 인정 어떻</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>EU전공 졸업 요건은 어떻게 되나요</td>\n      <td>논술형 종합시험으로 실시합니다.</td>\n      <td>[UK]</td>\n      <td>전공 졸업 요건</td>\n    </tr>\n  </tbody>\n</table>\n<p>125 rows × 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "space = r\"E:\\Programming\\python\\NLP\\howls_nlp\\Chatbot\\자료\\models\\soy_big_space_model\"\n",
    "stop = r'E:\\Programming\\python\\NLP\\howls_nlp\\Chatbot\\자료\\stop_words.txt'\n",
    "\n",
    "preprocess(merged_df, space, stop, \"preprocessed_made_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_df = pd.read_csv(r\"E:\\Programming\\python\\NLP\\howls_nlp\\Chatbot\\자료\\results\\preprocessed_data.csv\", encoding=\"cp949\")\n",
    "new_merged_df = pd.concat([origin_df, merged_df])\n",
    "new_merged_df.reset_index(drop=True, inplace=True)\n",
    "new_merged_df.to_csv(r\"E:\\Programming\\python\\NLP\\howls_nlp\\Chatbot\\자료\\results\\Q&A.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}